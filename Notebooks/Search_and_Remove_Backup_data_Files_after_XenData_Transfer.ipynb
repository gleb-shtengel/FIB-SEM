{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f533ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skimage version:  0.19.2\n",
      "scipy version:    1.9.1\n",
      "sklearn version:  1.0.2\n",
      "Open CV version:  4.10.0\n",
      "SIFT_gs version:  4.0.1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import fnmatch\n",
    "from tqdm.notebook import tqdm, tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask.distributed import Client, progress, get_task_stream, as_completed\n",
    "dask.config.set({'logging.distributed': 'error'})\n",
    "from IPython.display import IFrame\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from SIFT_gs.FIBSEM_SIFT_gs import FIBSEM_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a71984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bf55a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_file(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "        del_succesfull = True\n",
    "    except:\n",
    "        del_succesfull = False\n",
    "    return filename, del_succesfull\n",
    "\n",
    "def get_size_gs(filename):\n",
    "    try:\n",
    "        x = np.int64(os.path.getsize(filename))\n",
    "    except:\n",
    "        x = np.int64(0)\n",
    "    return filename, x\n",
    "\n",
    "def get_sizes_gs(filenames, **kwargs):\n",
    "\n",
    "    DASK_client = kwargs.get('DASK_client', '')\n",
    "    DASK_client_retries = kwargs.get('DASK_client_retries', 3)\n",
    "    max_futures = kwargs.get('max_futures', 100000)\n",
    "    try:\n",
    "        client_services = DASK_client.scheduler_info()['services']\n",
    "        if client_services:\n",
    "            try:\n",
    "                dport = client_services['dashboard']\n",
    "            except:\n",
    "                dport = client_services['bokeh']\n",
    "            status_update_address = 'http://localhost:{:d}/status'.format(dport)\n",
    "            print('DASK client exists. Will perform distributed computations')\n",
    "            print('Use ' + status_update_address +' to monitor DASK progress')\n",
    "            use_DASK = True\n",
    "        else:\n",
    "            print(time.strftime('%Y/%m/%d  %H:%M:%S')+'   DASK client does not exist. Will perform local computations')\n",
    "            use_DASK = False\n",
    "    except:\n",
    "        print(time.strftime('%Y/%m/%d  %H:%M:%S')+'   DASK client does not exist. Will perform local computations')\n",
    "        use_DASK = False\n",
    "\n",
    "    if use_DASK:\n",
    "        filenames = []\n",
    "        filesizes = []\n",
    "        DASK_batch = 0\n",
    "        while len(filenames) > max_futures:\n",
    "            print(time.strftime('%Y/%m/%d  %H:%M:%S')+'   Starting DASK batch {:d} with {:d} jobs, {:d} jobs remaining'.format(DASK_batch, max_futures, (len(filenames)-max_futures)))\n",
    "            futures = DASK_client.map(get_size_gs, filenames[0:max_futures])\n",
    "            filenames = filenames[max_futures:]\n",
    "            results = DASK_client.gather(futures)\n",
    "            DASK_client.cancel(futures)\n",
    "            filenames += [result[0] for result in results]\n",
    "            filesizes += [result[1] for result in results]\n",
    "        \n",
    "        if len(full_filenames_Jeiss3_copy) > 0:\n",
    "            print(time.strftime('%Y/%m/%d  %H:%M:%S')+'   Starting DASK batch {:d} with {:d} jobs'.format(DASK_batch, len(filenames)))\n",
    "            futures = DASK_client.map(get_size_gs, filenames)\n",
    "            filenames = filenames[max_futures:]\n",
    "            results = DASK_client.gather(futures)\n",
    "            DASK_client.cancel(futures)\n",
    "            filenames += [result[0] for result in results]\n",
    "            filesizes += [result[1] for result in results]\n",
    "    else:\n",
    "        filenames = ['' for x in np.arange(len(filenames))]\n",
    "        filesizes = np.zeros(len(filenames), dtype = np.int64)\n",
    "        for j, filename in enumerate(tqdm(filenames)):\n",
    "            filenames[j], filesizes[j] = get_size_gs(filename)\n",
    "\n",
    "    return filenames, filesizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c456fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b14f7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Local Port:    8787\n",
      "Use http://localhost:8787/status to monitor DASK progress\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"900px\"\n",
       "            src=\"http://localhost:8787/status\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x22102325820>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start / restart client\n",
    "try:\n",
    "    client.restart()\n",
    "except:\n",
    "    client = Client()\n",
    "    \n",
    "# setup a window to monitor the client progress\n",
    "try:\n",
    "    dport = client.scheduler_info()['services']['dashboard']\n",
    "except:\n",
    "    dport = client.scheduler_info()['services']['bokeh']\n",
    "print('Using Local Port:   ', dport)\n",
    "status_update_address0 = 'http://localhost:{:d}/status'.format(dport)\n",
    "print('Use ' + status_update_address0 +' to monitor DASK progress')\n",
    "status_update_address = 'http://localhost:{:d}/status'.format(dport)\n",
    "IFrame(src=status_update_address, width='100%', height='900px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e686854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e05256c7",
   "metadata": {},
   "source": [
    "# Analyze Directory \\nearline4\\fibsem\\Backup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d1e814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory: V:/Backup_data\n",
      "Total number of files in the root directory:       754569\n",
      "Total number of *.png files in the root directory: 211764\n",
      "Total number of *.csv files in the root directory: 299\n",
      "Total number of *.xlsx files in the root directory: 18\n",
      "Total number of files to copy to tape:       542805\n",
      "Total number of files to delete:       542488\n",
      "Total number of files to keep  :       212081\n",
      "Total number of files to delete (alt): 542488\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "root_dir_Backup_data = 'V:/Backup_data'\n",
    "\n",
    "full_filenames_Backup_data = [os.path.join(d, x) for d, dirs, files in os.walk(root_dir_Backup_data) for x in files]\n",
    "print('Root directory:', root_dir_Backup_data)\n",
    "num_tot = len(full_filenames_Backup_data)\n",
    "print('Total number of files in the root directory:      ', num_tot)\n",
    "full_PNG_filenames = fnmatch.filter(full_filenames_Backup_data, '*.png')\n",
    "num_PNG = len(full_PNG_filenames)\n",
    "full_CSV_files = fnmatch.filter(full_filenames_Backup_data, '*.csv')\n",
    "num_CSV = len(full_CSV_files)\n",
    "full_XLSX_files = fnmatch.filter(full_filenames_Backup_data, '*.xlsx')\n",
    "num_XLSX = len(full_XLSX_files)\n",
    "\n",
    "print('Total number of *.png files in the root directory:', num_PNG)\n",
    "print('Total number of *.csv files in the root directory:', num_CSV)\n",
    "print('Total number of *.xlsx files in the root directory:', num_XLSX)\n",
    "\n",
    "print('Total number of files to copy to tape:      ', (num_tot - num_PNG))\n",
    "print('Total number of files to delete:      ', (num_tot - (num_PNG + num_CSV + num_XLSX)))\n",
    "print('Total number of files to keep  :      ', num_PNG + num_CSV + num_XLSX)\n",
    "\n",
    "except_masks = ['png', 'csv', 'xlsx']\n",
    "filenames_to_delete_Backup_data = [file for file in full_filenames_Backup_data if np.array([file [-1*(len(except_mask)):] != except_mask for except_mask in except_masks]).all()]\n",
    "print('Total number of files to delete (alt):', len(filenames_to_delete_Backup_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae2a254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory: V:/Backup_data\n",
      "Total number of analyzed files in the root directory:         754569\n",
      "Total size on disk of analyzed files in the root directory:   174019315816137\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Using DASK. Use ' + status_update_address0 +' to monitor DASK progress')\n",
    "futures = client.map(get_size_gs, full_filenames_Backup_data, retries = 5)\n",
    "results = np.array(client.gather(futures))\n",
    "filenames_Backup_data = [result[0] for result in results]\n",
    "filesizes_Backup_data = [result[1] for result in results]\n",
    "\n",
    "print('Root directory:', root_dir_Backup_data)\n",
    "print('Total number of analyzed files in the root directory:        ', len(filenames_Backup_data))\n",
    "print('Total size on disk of analyzed files in the root directory:  ', np.sum(np.int64(filesizes_Backup_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c59972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
